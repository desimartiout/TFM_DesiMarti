# 游닇 TFM Desiderio Mart칤 Alcaraz - Grado en Ciencia de Datos (UOC - Universitat Oberta de Catalunya).

Bienvenido al Chatbot especializado en b칰squeda de ayudas y subvenciones 칰blicas del Gobierno de Espa침a basado en RAG con LLMs locales.

### 游 Caracter칤sticas principales
- **Consultas bd vectoriales:** Uso de b칰squedas vectoriales con Chromadb.
- **Local LLM** B칰squeda de informaci칩n en documentos mediante el uso de bases de datos vectoriales y LLM local  con Ollama o OPENAI.


### 游 Como comenzar
1. Clonar el repositorio: `git clone https://github.com/desimartiout/TFM_DesiMarti.git`
2. Instalar dependencias: `pip install -r requirements.txt`
3. Configurar fichero de par치metros en `src/constants.py` para elegir el modelo de embeddings y el modelo de LLM.
4. Ejecutar la aplicaci칩n Streamlit: `streamlit run Inicio.py`

## 游닂 OLLAMA

### Ollama instalar modelo en local desde l칤nea de comando on ollama
ollama pull llama3.2:1b

Si queremos hacer una copia del modelo para no trabajar directamente sobre el descargado lo podemos hacer as칤
ollama cp llamaAyudas:latest

### Arrancar el modelo con OLlama
ollama run llamaAyudas:latest

## 游닂 OPENAI

# SI QUIERES VER SI TIENES LA VARAIBLE DE ENTORNO PUEDES USAR ESTE C칍DIGO
import os

Cargar la clave desde las variables de entorno
openai_api_key = os.getenv("OPENAI_API_KEY")

if not openai_api_key:
    raise ValueError("La clave de OpenAI no est치 configurada como variable de entorno.")

Usar la clave en tu c칩digo
import openai
openai.api_key = openai_api_key -->

# 游닂 Web Chatbot
Directorio //
Directorio de logs /logs/
Fichero de configuraci칩n `src/constants.py`

### Configuraci칩n


### Ejecutar la aplicaci칩n Streamlit

Desde la directorio principal raiz ejecutar el comando `streamlit run Inicio.py`

# 游닂 Web Scrapping de la web de ayudas
Directorio /scrapping/
Directorio de logs /scrapping/logs/
Fichero de configuraci칩n /scrapping/constantes.py

### Configuraci칩n
Aqu칤 se especifican las rutas del API de la web de ayudas, los directorios de logs y donde se almacenan los documentos y la plantilla YAML para transformar el JSON resultado de la llamada a un formato m치s entendible

Se puede tambier especificar los par치metros para la llamada al API
PAGE_SIZE: Tama침o de resultados por p치gina
TOTAL_PAGES: N칰mero total de p치ginas a procesar

### Ejecuci칩n

Desde la ruta /scrapping/ ejecutar el comando

**python.exe obtenerDatos.py**

# 游닂  RAGAS - Evaluar el modelo

### Configuraci칩n
Directorio /ragas_eval/
Directorio de logs /ragas_eval/logs/
Fichero de configuraci칩n /ragas_eval/constantes.py

Elegir el LLM a utilizar en la evaluaci칩n OPENAI / OLLAMA
RAGAS_LLM_SELECCIONADO = RAGAS_LLM_TIPOMODELO_OPENAI / RAGAS_LLM_TIPOMODELO_OLLAMA

Los nombres de los modelos deben estar especificados en estas constantes
RAGAS_OPENAI_MODEL_NAME = "gpt-3.5-turbo"
RAGAS_OLLAMA_MODEL_NAME = "llamaAyudas:latest"

### Ejecuci칩n

Desde la ruta /ragas_eval/ ejecutar el comando

**python.exe evaluar.py 2024_12_14_ragas.json**

Nota: El fichero a evaluar debe estar en el directorio /ragas_eval/datasets/

Esto genera un fichero csv en el directorio /ragas_eval/results/ con los resultados de la evaluaci칩n cuyo nombre contiene la fecha y hora de la evaluaci칩n, por ejemplo 2024_12_09_19_38_39_ragas_results.csv

El formato del fichero es este:
"user_input";"retrieved_contexts";"response";"reference";"context_recall";"factual_correctness";"faithfulness";"semantic_similarity";"answer_relevancy";"context_precision"

Donde los campos "user_input";"retrieved_contexts";"response";"reference" contienen los datos evaluados y los campos "context_recall";"factual_correctness";"faithfulness";"semantic_similarity";"answer_relevancy";"context_precision" contienen los resultados de la evaluaci칩n.

### 游닂 Referencias
**Sistema Nacional de Publicidad de Subvenciones y Ayudas P칰blicas** (https://www.pap.hacienda.gob.es/bdnstrans/)
**Streamlit** (https://streamlit.io/)
**RAGAS** (https://docs.ragas.io/)
**CHROMA DB** (https://www.trychroma.com/)